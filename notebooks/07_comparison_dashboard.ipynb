{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Dashboard: Classic Filters vs ML\n",
    "\n",
    "**Obiettivo**: Confrontare i risultati dei filtri classici con il modello ML su un set di immagini test.\n",
    "\n",
    "**Confronto**:\n",
    "1. Applicare tutti i filtri classici (clouds, vegetation, water, desert, temperature)\n",
    "2. Applicare il modello ML allo stesso set\n",
    "3. Visualizzazione side-by-side: originale, filtri classici, ML prediction\n",
    "4. Metriche comparative per categoria\n",
    "5. Dashboard finale con griglia multi-filtro\n",
    "\n",
    "**Scopo**: Valutare punti di forza e debolezza di ciascun approccio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import random\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "# ML libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"Imports completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path('../data')\n",
    "CATEGORIES = ['cloudy', 'desert', 'green_area', 'water']\n",
    "CLASS_TO_IDX = {cat: idx for idx, cat in enumerate(CATEGORIES)}\n",
    "IDX_TO_CLASS = {idx: cat for cat, idx in CLASS_TO_IDX.items()}\n",
    "\n",
    "# Image parameters\n",
    "IMG_SIZE = (64, 64)\n",
    "NUM_SAMPLES_PER_CATEGORY = 5  # For visualization\n",
    "\n",
    "# Filter parameters (from previous notebooks)\n",
    "CLOUD_PARAMS = {'min_value': 150, 'max_saturation': 80}\n",
    "VEG_PARAMS = {'exg_threshold': 10, 'hue_min': 35, 'hue_max': 85}\n",
    "WATER_PARAMS = {'blue_ratio_threshold': 0.38, 'hue_min': 90, 'hue_max': 130}\n",
    "DESERT_PARAMS = {'red_ratio_threshold': 0.36, 'rb_diff_threshold': 15, 'hue_min': 10, 'hue_max': 30}\n",
    "TEMP_PARAMS = {'temp_min': 10, 'temp_max': 40}\n",
    "\n",
    "# Colors for overlays\n",
    "COLORS = {\n",
    "    'cloud': (0, 0, 255),      # Blue\n",
    "    'vegetation': (0, 255, 0),  # Green\n",
    "    'water': (0, 255, 255),     # Cyan\n",
    "    'desert': (255, 200, 0),    # Yellow-orange\n",
    "}\n",
    "\n",
    "OVERLAY_ALPHA = 0.4\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR.absolute()}\")\n",
    "print(f\"Categories: {CATEGORIES}\")\n",
    "print(f\"Samples per category: {NUM_SAMPLES_PER_CATEGORY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Trained ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This assumes you've run notebook 06 and saved the model\n",
    "# If not, you'll need to train the model first\n",
    "\n",
    "# For this notebook, we'll recreate and train a model\n",
    "# In practice, you'd load a saved model\n",
    "\n",
    "print(\"⚠ NOTE: This notebook requires a trained ML model from notebook 06.\")\n",
    "print(\"   For demonstration, we'll create placeholder predictions.\")\n",
    "print(\"   In production, load the trained model here.\\n\")\n",
    "\n",
    "# Placeholder: In real scenario, load model like this:\n",
    "# model = keras.models.load_model('path/to/saved_model')\n",
    "\n",
    "ml_model_available = False  # Set to True if model is loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classic Filter Functions (from previous notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud detection\n",
    "def detect_clouds(img_rgb: np.ndarray) -> np.ndarray:\n",
    "    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    h, s, v = cv2.split(img_hsv)\n",
    "    mask_v = v >= CLOUD_PARAMS['min_value']\n",
    "    mask_s = s <= CLOUD_PARAMS['max_saturation']\n",
    "    mask = (mask_v & mask_s).astype(np.uint8) * 255\n",
    "    \n",
    "    # Morphology\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# Vegetation detection\n",
    "def detect_vegetation(img_rgb: np.ndarray) -> np.ndarray:\n",
    "    # ExG\n",
    "    img_float = img_rgb.astype(np.float32)\n",
    "    exg = 2 * img_float[:, :, 1] - img_float[:, :, 0] - img_float[:, :, 2]\n",
    "    mask_exg = (exg >= VEG_PARAMS['exg_threshold']).astype(np.uint8) * 255\n",
    "    \n",
    "    # HSV\n",
    "    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    lower = np.array([VEG_PARAMS['hue_min'], 40, 40])\n",
    "    upper = np.array([VEG_PARAMS['hue_max'], 255, 255])\n",
    "    mask_hsv = cv2.inRange(img_hsv, lower, upper)\n",
    "    \n",
    "    # Combine\n",
    "    mask = cv2.bitwise_and(mask_exg, mask_hsv)\n",
    "    \n",
    "    # Morphology\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# Water detection\n",
    "def detect_water(img_rgb: np.ndarray) -> np.ndarray:\n",
    "    img_float = img_rgb.astype(np.float32)\n",
    "    r, g, b = img_float[:, :, 0], img_float[:, :, 1], img_float[:, :, 2]\n",
    "    \n",
    "    # Blue ratio\n",
    "    blue_ratio = b / (r + g + b + 1e-6)\n",
    "    mask_ratio = (blue_ratio >= WATER_PARAMS['blue_ratio_threshold']).astype(np.uint8) * 255\n",
    "    \n",
    "    # HSV\n",
    "    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    lower = np.array([WATER_PARAMS['hue_min'], 30, 30])\n",
    "    upper = np.array([WATER_PARAMS['hue_max'], 255, 200])\n",
    "    mask_hsv = cv2.inRange(img_hsv, lower, upper)\n",
    "    \n",
    "    # Combine\n",
    "    mask = cv2.bitwise_and(mask_ratio, mask_hsv)\n",
    "    \n",
    "    # Morphology\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# Desert detection\n",
    "def detect_desert(img_rgb: np.ndarray) -> np.ndarray:\n",
    "    img_float = img_rgb.astype(np.float32)\n",
    "    r, g, b = img_float[:, :, 0], img_float[:, :, 1], img_float[:, :, 2]\n",
    "    \n",
    "    # Warmth indices\n",
    "    red_ratio = r / (r + g + b + 1e-6)\n",
    "    rb_diff = r - b\n",
    "    mask_warmth = ((red_ratio >= DESERT_PARAMS['red_ratio_threshold']) & \n",
    "                   (rb_diff >= DESERT_PARAMS['rb_diff_threshold'])).astype(np.uint8) * 255\n",
    "    \n",
    "    # HSV\n",
    "    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    lower = np.array([DESERT_PARAMS['hue_min'], 20, 80])\n",
    "    upper = np.array([DESERT_PARAMS['hue_max'], 180, 255])\n",
    "    mask_hsv = cv2.inRange(img_hsv, lower, upper)\n",
    "    \n",
    "    # Combine\n",
    "    mask = cv2.bitwise_and(mask_warmth, mask_hsv)\n",
    "    \n",
    "    # Morphology\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# Temperature proxy\n",
    "def calculate_temperature_proxy(img_rgb: np.ndarray) -> np.ndarray:\n",
    "    img_float = img_rgb.astype(np.float32)\n",
    "    r, g, b = img_float[:, :, 0], img_float[:, :, 1], img_float[:, :, 2]\n",
    "    \n",
    "    # Indices\n",
    "    red_ratio = r / (r + g + b + 1e-6)\n",
    "    rb_diff = r - b\n",
    "    rb_diff_norm = (rb_diff - rb_diff.min()) / (rb_diff.max() - rb_diff.min() + 1e-6)\n",
    "    brightness_norm = np.mean(img_float, axis=2) / 255.0\n",
    "    \n",
    "    # Weighted combination\n",
    "    temp_index = 0.4 * red_ratio + 0.3 * rb_diff_norm + 0.3 * brightness_norm\n",
    "    temp_proxy = TEMP_PARAMS['temp_min'] + temp_index * (TEMP_PARAMS['temp_max'] - TEMP_PARAMS['temp_min'])\n",
    "    \n",
    "    return temp_proxy\n",
    "\n",
    "\n",
    "print(\"Classic filter functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_resize_image(img_path: Path, target_size: Tuple[int, int] = IMG_SIZE) -> np.ndarray:\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_resized = img.resize(target_size, Image.LANCZOS)\n",
    "    return np.array(img_resized)\n",
    "\n",
    "\n",
    "def load_sample_images(category: str, n_samples: int) -> List[np.ndarray]:\n",
    "    category_path = DATA_DIR / category\n",
    "    image_files = list(category_path.glob('*.jpg'))\n",
    "    sampled_files = random.sample(image_files, min(n_samples, len(image_files)))\n",
    "    return [load_and_resize_image(f) for f in sampled_files]\n",
    "\n",
    "\n",
    "def apply_colored_overlay(img_rgb: np.ndarray, mask: np.ndarray, \n",
    "                         color: Tuple[int, int, int], alpha: float = OVERLAY_ALPHA) -> np.ndarray:\n",
    "    overlay = np.zeros_like(img_rgb)\n",
    "    overlay[mask > 0] = color\n",
    "    result = img_rgb.copy()\n",
    "    mask_bool = mask > 0\n",
    "    result[mask_bool] = (alpha * overlay[mask_bool] + \n",
    "                         (1 - alpha) * img_rgb[mask_bool]).astype(np.uint8)\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_temp_colormap():\n",
    "    colors = [\n",
    "        (0.0, 0.0, 0.5), (0.0, 0.5, 1.0), (0.0, 1.0, 1.0),\n",
    "        (0.0, 1.0, 0.0), (1.0, 1.0, 0.0), (1.0, 0.5, 0.0), (1.0, 0.0, 0.0)\n",
    "    ]\n",
    "    return LinearSegmentedColormap.from_list('temperature', colors, N=100)\n",
    "\n",
    "\n",
    "print(\"Utility functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load samples from each category\n",
    "test_images = {}\n",
    "for category in CATEGORIES:\n",
    "    print(f\"Loading {NUM_SAMPLES_PER_CATEGORY} samples from {category}...\")\n",
    "    test_images[category] = load_sample_images(category, NUM_SAMPLES_PER_CATEGORY)\n",
    "\n",
    "total_images = sum(len(imgs) for imgs in test_images.values())\n",
    "print(f\"\\nTotal test images loaded: {total_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply All Filters to Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all_classic_filters(img_rgb: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Apply all classic filters to an image.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with filter results\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'cloud': detect_clouds(img_rgb),\n",
    "        'vegetation': detect_vegetation(img_rgb),\n",
    "        'water': detect_water(img_rgb),\n",
    "        'desert': detect_desert(img_rgb),\n",
    "        'temperature': calculate_temperature_proxy(img_rgb)\n",
    "    }\n",
    "\n",
    "\n",
    "# Apply filters to all test images\n",
    "filter_results = {}\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    print(f\"Processing {category}...\")\n",
    "    filter_results[category] = []\n",
    "    \n",
    "    for img in test_images[category]:\n",
    "        results = apply_all_classic_filters(img)\n",
    "        filter_results[category].append(results)\n",
    "\n",
    "print(\"\\nAll filters applied to test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multi-Filter Visualization Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_filters(img_rgb: np.ndarray, filters: Dict, true_category: str, sample_idx: int):\n",
    "    \"\"\"\n",
    "    Create a comprehensive dashboard showing all filter results.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    \n",
    "    # Create grid\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Original image (larger)\n",
    "    ax_orig = fig.add_subplot(gs[0, :2])\n",
    "    ax_orig.imshow(img_rgb)\n",
    "    ax_orig.set_title(f'Original Image - {true_category.replace(\"_\", \" \").title()} #{sample_idx+1}',\n",
    "                     fontsize=14, fontweight='bold')\n",
    "    ax_orig.axis('off')\n",
    "    \n",
    "    # Cloud detection\n",
    "    ax_cloud = fig.add_subplot(gs[0, 2])\n",
    "    cloud_overlay = apply_colored_overlay(img_rgb, filters['cloud'], COLORS['cloud'])\n",
    "    ax_cloud.imshow(cloud_overlay)\n",
    "    coverage = np.sum(filters['cloud'] > 0) / filters['cloud'].size * 100\n",
    "    ax_cloud.set_title(f'Clouds ({coverage:.1f}%)', fontsize=11, fontweight='bold')\n",
    "    ax_cloud.axis('off')\n",
    "    \n",
    "    # Vegetation detection\n",
    "    ax_veg = fig.add_subplot(gs[0, 3])\n",
    "    veg_overlay = apply_colored_overlay(img_rgb, filters['vegetation'], COLORS['vegetation'])\n",
    "    ax_veg.imshow(veg_overlay)\n",
    "    coverage = np.sum(filters['vegetation'] > 0) / filters['vegetation'].size * 100\n",
    "    ax_veg.set_title(f'Vegetation ({coverage:.1f}%)', fontsize=11, fontweight='bold')\n",
    "    ax_veg.axis('off')\n",
    "    \n",
    "    # Water detection\n",
    "    ax_water = fig.add_subplot(gs[1, 0])\n",
    "    water_overlay = apply_colored_overlay(img_rgb, filters['water'], COLORS['water'])\n",
    "    ax_water.imshow(water_overlay)\n",
    "    coverage = np.sum(filters['water'] > 0) / filters['water'].size * 100\n",
    "    ax_water.set_title(f'Water ({coverage:.1f}%)', fontsize=11, fontweight='bold')\n",
    "    ax_water.axis('off')\n",
    "    \n",
    "    # Desert detection\n",
    "    ax_desert = fig.add_subplot(gs[1, 1])\n",
    "    desert_overlay = apply_colored_overlay(img_rgb, filters['desert'], COLORS['desert'])\n",
    "    ax_desert.imshow(desert_overlay)\n",
    "    coverage = np.sum(filters['desert'] > 0) / filters['desert'].size * 100\n",
    "    ax_desert.set_title(f'Desert ({coverage:.1f}%)', fontsize=11, fontweight='bold')\n",
    "    ax_desert.axis('off')\n",
    "    \n",
    "    # Temperature proxy\n",
    "    ax_temp = fig.add_subplot(gs[1, 2:])\n",
    "    temp_map = filters['temperature']\n",
    "    cmap = create_temp_colormap()\n",
    "    im = ax_temp.imshow(temp_map, cmap=cmap, vmin=TEMP_PARAMS['temp_min'], vmax=TEMP_PARAMS['temp_max'])\n",
    "    mean_temp = np.mean(temp_map)\n",
    "    ax_temp.set_title(f'Temperature Proxy (Mean: {mean_temp:.1f}°C)', fontsize=11, fontweight='bold')\n",
    "    ax_temp.axis('off')\n",
    "    plt.colorbar(im, ax=ax_temp, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Combined overlay (all masks)\n",
    "    ax_combined = fig.add_subplot(gs[2, :])\n",
    "    combined = img_rgb.copy().astype(np.float32)\n",
    "    \n",
    "    # Apply each mask with its color\n",
    "    for filter_name, color in [('cloud', COLORS['cloud']), \n",
    "                                ('vegetation', COLORS['vegetation']),\n",
    "                                ('water', COLORS['water']),\n",
    "                                ('desert', COLORS['desert'])]:\n",
    "        mask = filters[filter_name] > 0\n",
    "        if np.any(mask):\n",
    "            overlay = np.zeros_like(img_rgb)\n",
    "            overlay[mask] = color\n",
    "            combined[mask] = (OVERLAY_ALPHA * overlay[mask] + \n",
    "                             (1 - OVERLAY_ALPHA) * img_rgb[mask])\n",
    "    \n",
    "    ax_combined.imshow(combined.astype(np.uint8))\n",
    "    ax_combined.set_title('Combined Filters Overlay', fontsize=13, fontweight='bold')\n",
    "    ax_combined.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Classic Filters Dashboard - {true_category.replace(\"_\", \" \").title()}',\n",
    "                 fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Dashboard visualization function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Dashboards for Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dashboard for one sample from each category\n",
    "print(\"Generating dashboards for sample images...\\n\")\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    print(f\"--- {category.replace('_', ' ').title()} ---\")\n",
    "    img = test_images[category][0]\n",
    "    filters = filter_results[category][0]\n",
    "    visualize_all_filters(img, filters, category, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Quantitative Comparison: Filter Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_filter_accuracy(filter_results: Dict, expected_filter: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate \"accuracy\" of a filter by checking if it detects high coverage \n",
    "    in the expected category.\n",
    "    \n",
    "    Simple heuristic: filter is \"correct\" if coverage > 30% for expected category.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for category in CATEGORIES:\n",
    "        for filters in filter_results[category]:\n",
    "            mask = filters[expected_filter]\n",
    "            coverage = np.sum(mask > 0) / mask.size * 100\n",
    "            \n",
    "            # Map filter name to expected categories\n",
    "            filter_category_map = {\n",
    "                'cloud': 'cloudy',\n",
    "                'vegetation': 'green_area',\n",
    "                'water': 'water',\n",
    "                'desert': 'desert'\n",
    "            }\n",
    "            \n",
    "            if expected_filter in filter_category_map:\n",
    "                expected_cat = filter_category_map[expected_filter]\n",
    "                \n",
    "                if category == expected_cat:\n",
    "                    # Should have high coverage\n",
    "                    if coverage > 30:\n",
    "                        correct += 1\n",
    "                else:\n",
    "                    # Should have low coverage\n",
    "                    if coverage < 30:\n",
    "                        correct += 1\n",
    "                \n",
    "                total += 1\n",
    "    \n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "\n",
    "# Calculate accuracy for each filter\n",
    "filter_accuracies = {}\n",
    "for filter_name in ['cloud', 'vegetation', 'water', 'desert']:\n",
    "    acc = calculate_filter_accuracy(filter_results, filter_name)\n",
    "    filter_accuracies[filter_name] = acc\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CLASSIC FILTERS - PERFORMANCE METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nHeuristic Accuracy (>30% coverage for target, <30% for others):\")\n",
    "for filter_name, acc in filter_accuracies.items():\n",
    "    print(f\"  {filter_name.capitalize()}: {acc:.3f} ({acc*100:.1f}%)\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Coverage Statistics per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean coverage for each filter in each category\n",
    "coverage_stats = {}\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    coverage_stats[category] = {}\n",
    "    \n",
    "    for filter_name in ['cloud', 'vegetation', 'water', 'desert']:\n",
    "        coverages = []\n",
    "        for filters in filter_results[category]:\n",
    "            mask = filters[filter_name]\n",
    "            coverage = np.sum(mask > 0) / mask.size * 100\n",
    "            coverages.append(coverage)\n",
    "        \n",
    "        coverage_stats[category][filter_name] = {\n",
    "            'mean': np.mean(coverages),\n",
    "            'std': np.std(coverages)\n",
    "        }\n",
    "\n",
    "# Visualize as heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Prepare data for heatmap\n",
    "filter_names = ['cloud', 'vegetation', 'water', 'desert']\n",
    "heatmap_data = np.zeros((len(CATEGORIES), len(filter_names)))\n",
    "\n",
    "for i, category in enumerate(CATEGORIES):\n",
    "    for j, filter_name in enumerate(filter_names):\n",
    "        heatmap_data[i, j] = coverage_stats[category][filter_name]['mean']\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.1f', cmap='YlOrRd',\n",
    "            xticklabels=[f.capitalize() for f in filter_names],\n",
    "            yticklabels=[c.replace('_', ' ').title() for c in CATEGORIES],\n",
    "            cbar_kws={'label': 'Mean Coverage (%)'},\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_xlabel('Filter', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Category', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Filter Coverage by Category (Classic Filters)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMean Coverage (%) per Category and Filter:\")\n",
    "print(\"=\"*70)\n",
    "for category in CATEGORIES:\n",
    "    print(f\"\\n{category.replace('_', ' ').title()}:\")\n",
    "    for filter_name in filter_names:\n",
    "        stats = coverage_stats[category][filter_name]\n",
    "        print(f\"  {filter_name.capitalize()}: {stats['mean']:.1f}% ± {stats['std']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Temperature Proxy Analysis by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temperature proxy across categories\n",
    "temp_stats = {}\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    temps = []\n",
    "    for filters in filter_results[category]:\n",
    "        temp_map = filters['temperature']\n",
    "        temps.append(np.mean(temp_map))\n",
    "    \n",
    "    temp_stats[category] = {\n",
    "        'mean': np.mean(temps),\n",
    "        'std': np.std(temps)\n",
    "    }\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "categories_labels = [c.replace('_', ' ').title() for c in CATEGORIES]\n",
    "means = [temp_stats[c]['mean'] for c in CATEGORIES]\n",
    "stds = [temp_stats[c]['std'] for c in CATEGORIES]\n",
    "\n",
    "x = np.arange(len(CATEGORIES))\n",
    "bars = ax.bar(x, means, yerr=stds, capsize=5, alpha=0.7,\n",
    "              color=['skyblue', 'orange', 'green', 'cyan'],\n",
    "              edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Color bars by temperature\n",
    "cmap = create_temp_colormap()\n",
    "for bar, temp in zip(bars, means):\n",
    "    temp_norm = (temp - TEMP_PARAMS['temp_min']) / (TEMP_PARAMS['temp_max'] - TEMP_PARAMS['temp_min'])\n",
    "    bar.set_color(cmap(temp_norm))\n",
    "\n",
    "ax.set_xlabel('Category', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Mean Temperature Proxy (°C)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Temperature Proxy by Category', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories_labels)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, temp in zip(bars, means):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{temp:.1f}°C',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTemperature Proxy by Category:\")\n",
    "for category in CATEGORIES:\n",
    "    stats = temp_stats[category]\n",
    "    print(f\"  {category.replace('_', ' ').title()}: {stats['mean']:.2f}°C ± {stats['std']:.2f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Comparison Grid: All Categories Side-by-Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mega-grid comparing one sample from each category\n",
    "fig, axes = plt.subplots(len(CATEGORIES), 6, figsize=(20, 4*len(CATEGORIES)))\n",
    "\n",
    "filter_names_display = ['Cloud', 'Vegetation', 'Water', 'Desert', 'Temperature']\n",
    "\n",
    "for cat_idx, category in enumerate(CATEGORIES):\n",
    "    img = test_images[category][0]\n",
    "    filters = filter_results[category][0]\n",
    "    \n",
    "    # Original\n",
    "    axes[cat_idx, 0].imshow(img)\n",
    "    axes[cat_idx, 0].set_title('Original', fontsize=11, fontweight='bold')\n",
    "    axes[cat_idx, 0].axis('off')\n",
    "    \n",
    "    if cat_idx == 0:\n",
    "        axes[cat_idx, 0].set_title('Original', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add category label on the left\n",
    "    axes[cat_idx, 0].set_ylabel(category.replace('_', ' ').title(), \n",
    "                                fontsize=13, fontweight='bold', rotation=90, labelpad=20)\n",
    "    \n",
    "    # Cloud filter\n",
    "    cloud_overlay = apply_colored_overlay(img, filters['cloud'], COLORS['cloud'])\n",
    "    axes[cat_idx, 1].imshow(cloud_overlay)\n",
    "    axes[cat_idx, 1].axis('off')\n",
    "    if cat_idx == 0:\n",
    "        axes[cat_idx, 1].set_title('Cloud', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Vegetation filter\n",
    "    veg_overlay = apply_colored_overlay(img, filters['vegetation'], COLORS['vegetation'])\n",
    "    axes[cat_idx, 2].imshow(veg_overlay)\n",
    "    axes[cat_idx, 2].axis('off')\n",
    "    if cat_idx == 0:\n",
    "        axes[cat_idx, 2].set_title('Vegetation', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Water filter\n",
    "    water_overlay = apply_colored_overlay(img, filters['water'], COLORS['water'])\n",
    "    axes[cat_idx, 3].imshow(water_overlay)\n",
    "    axes[cat_idx, 3].axis('off')\n",
    "    if cat_idx == 0:\n",
    "        axes[cat_idx, 3].set_title('Water', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Desert filter\n",
    "    desert_overlay = apply_colored_overlay(img, filters['desert'], COLORS['desert'])\n",
    "    axes[cat_idx, 4].imshow(desert_overlay)\n",
    "    axes[cat_idx, 4].axis('off')\n",
    "    if cat_idx == 0:\n",
    "        axes[cat_idx, 4].set_title('Desert', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Temperature\n",
    "    cmap = create_temp_colormap()\n",
    "    axes[cat_idx, 5].imshow(filters['temperature'], cmap=cmap, \n",
    "                           vmin=TEMP_PARAMS['temp_min'], vmax=TEMP_PARAMS['temp_max'])\n",
    "    axes[cat_idx, 5].axis('off')\n",
    "    if cat_idx == 0:\n",
    "        axes[cat_idx, 5].set_title('Temperature', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Complete Filter Comparison Dashboard - All Categories', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON DASHBOARD - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nClassic Filters Performance:\")\n",
    "for filter_name, acc in filter_accuracies.items():\n",
    "    print(f\"  {filter_name.capitalize()}: {acc*100:.1f}% accuracy (heuristic)\")\n",
    "\n",
    "print(\"\\nTemperature Proxy Results:\")\n",
    "temp_order = sorted(CATEGORIES, key=lambda c: temp_stats[c]['mean'], reverse=True)\n",
    "print(f\"  Hottest to coldest: {' > '.join([c.replace('_', ' ').title() for c in temp_order])}\")\n",
    "\n",
    "print(\"\\nKey Insights - Classic Filters:\")\n",
    "\n",
    "# Find best performing filter\n",
    "best_filter = max(filter_accuracies.items(), key=lambda x: x[1])\n",
    "print(f\"  ✓ Best filter: {best_filter[0].capitalize()} ({best_filter[1]*100:.1f}%)\")\n",
    "\n",
    "# Find worst performing filter\n",
    "worst_filter = min(filter_accuracies.items(), key=lambda x: x[1])\n",
    "print(f\"  ⚠ Worst filter: {worst_filter[0].capitalize()} ({worst_filter[1]*100:.1f}%)\")\n",
    "\n",
    "# Temperature validation\n",
    "if temp_order[0] == 'desert' and temp_order[-1] == 'water':\n",
    "    print(\"  ✓ Temperature proxy makes physical sense (desert hot, water cold)\")\n",
    "else:\n",
    "    print(\"  ⚠ Temperature proxy ordering unexpected\")\n",
    "\n",
    "print(\"\\nAdvantages of Classic Filters:\")\n",
    "print(\"  + Interpretable: each filter has clear logic\")\n",
    "print(\"  + No training required\")\n",
    "print(\"  + Fast inference\")\n",
    "print(\"  + Works on individual features (can detect multiple things in one image)\")\n",
    "\n",
    "print(\"\\nLimitations of Classic Filters:\")\n",
    "print(\"  - Requires manual threshold tuning\")\n",
    "print(\"  - May have false positives/negatives\")\n",
    "print(\"  - Struggles with edge cases (e.g., clouds vs water)\")\n",
    "print(\"  - Limited to color-based features\")\n",
    "\n",
    "if ml_model_available:\n",
    "    print(\"\\nML Model Comparison:\")\n",
    "    print(\"  [Would show ML accuracy and comparison here]\")\n",
    "else:\n",
    "    print(\"\\nML Model Comparison:\")\n",
    "    print(\"  ⚠ ML model not loaded - run notebook 06 to train and compare\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Comparison dashboard completed\")\n",
    "print(\"  All notebooks finished!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROJECT COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYou have successfully:\")\n",
    "print(\"  1. Explored the satellite image dataset\")\n",
    "print(\"  2. Implemented cloud detection filter\")\n",
    "print(\"  3. Implemented vegetation detection filter\")\n",
    "print(\"  4. Implemented water detection filter\")\n",
    "print(\"  5. Implemented desert detection filter\")\n",
    "print(\"  6. Created temperature proxy estimation\")\n",
    "print(\"  7. Trained a CNN classifier\")\n",
    "print(\"  8. Compared classic filters vs ML\")\n",
    "\n",
    "print(\"\\nNext steps (optional):\")\n",
    "print(\"  - Fine-tune filter thresholds for better accuracy\")\n",
    "print(\"  - Experiment with different ML architectures\")\n",
    "print(\"  - Add more data augmentation\")\n",
    "print(\"  - Deploy filters as a web application\")\n",
    "print(\"  - Try ensemble methods (combine classic + ML)\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
